{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df=pd.read_csv('dataset/papers.csv',engine='c', error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'myself',\n",
       " 'those',\n",
       " 's',\n",
       " \"shan't\",\n",
       " 'where',\n",
       " 'no',\n",
       " 'they',\n",
       " 'now',\n",
       " 'all',\n",
       " 'shouldn',\n",
       " 'sample',\n",
       " 'these',\n",
       " 'before',\n",
       " 'him',\n",
       " \"doesn't\",\n",
       " \"won't\",\n",
       " 'other',\n",
       " 'or',\n",
       " 'few',\n",
       " 'how',\n",
       " 'y',\n",
       " \"hadn't\",\n",
       " 'yourself',\n",
       " 'too',\n",
       " \"mightn't\",\n",
       " 'than',\n",
       " 'ourselves',\n",
       " 'over',\n",
       " 'any',\n",
       " 'o',\n",
       " 'the',\n",
       " 'nor',\n",
       " 'mightn',\n",
       " 'an',\n",
       " 'eight',\n",
       " 'seven',\n",
       " 'if',\n",
       " 'have',\n",
       " 'five',\n",
       " 'some',\n",
       " 'there',\n",
       " 'being',\n",
       " 'off',\n",
       " 'your',\n",
       " 'figure',\n",
       " 're',\n",
       " 'don',\n",
       " \"hasn't\",\n",
       " \"couldn't\",\n",
       " 'needn',\n",
       " 'about',\n",
       " \"that'll\",\n",
       " 've',\n",
       " 'that',\n",
       " 'did',\n",
       " 'he',\n",
       " 'against',\n",
       " 'theirs',\n",
       " 'itself',\n",
       " 'at',\n",
       " 'can',\n",
       " 'do',\n",
       " 'didn',\n",
       " 'own',\n",
       " 'show',\n",
       " 'to',\n",
       " 'then',\n",
       " 'as',\n",
       " 'up',\n",
       " 'is',\n",
       " 'one',\n",
       " \"you're\",\n",
       " 'just',\n",
       " 'ain',\n",
       " \"weren't\",\n",
       " 'you',\n",
       " 'four',\n",
       " 'out',\n",
       " 'doesn',\n",
       " 'which',\n",
       " 'yourselves',\n",
       " 'be',\n",
       " 't',\n",
       " 'above',\n",
       " 'only',\n",
       " 'fig',\n",
       " 'hers',\n",
       " 'for',\n",
       " 'she',\n",
       " 'when',\n",
       " 'until',\n",
       " 'very',\n",
       " 'will',\n",
       " 'hasn',\n",
       " 'weren',\n",
       " 'here',\n",
       " 'under',\n",
       " 'again',\n",
       " 'his',\n",
       " 'were',\n",
       " 'me',\n",
       " 'down',\n",
       " 'in',\n",
       " 'ma',\n",
       " 'using',\n",
       " 'from',\n",
       " 'm',\n",
       " 'through',\n",
       " 'doing',\n",
       " 'its',\n",
       " \"didn't\",\n",
       " 'my',\n",
       " 'had',\n",
       " \"wasn't\",\n",
       " 'her',\n",
       " 'such',\n",
       " 'more',\n",
       " 'hadn',\n",
       " \"needn't\",\n",
       " 'by',\n",
       " 'won',\n",
       " 'been',\n",
       " 'll',\n",
       " 'shan',\n",
       " 'we',\n",
       " 'between',\n",
       " \"should've\",\n",
       " 'themselves',\n",
       " 'two',\n",
       " 'isn',\n",
       " 'not',\n",
       " 'of',\n",
       " 'nine',\n",
       " 'while',\n",
       " 'same',\n",
       " 'aren',\n",
       " 'haven',\n",
       " 'three',\n",
       " 'wasn',\n",
       " 'couldn',\n",
       " 'does',\n",
       " 'also',\n",
       " 'their',\n",
       " 'should',\n",
       " \"isn't\",\n",
       " 'result',\n",
       " 'ours',\n",
       " 'on',\n",
       " 'himself',\n",
       " 'but',\n",
       " \"she's\",\n",
       " 'both',\n",
       " 'below',\n",
       " 'am',\n",
       " \"haven't\",\n",
       " 'wouldn',\n",
       " 'them',\n",
       " 'a',\n",
       " 'image',\n",
       " 'because',\n",
       " \"don't\",\n",
       " 'with',\n",
       " 'was',\n",
       " 'who',\n",
       " 'are',\n",
       " 'mustn',\n",
       " 'what',\n",
       " 'each',\n",
       " 'large',\n",
       " 'after',\n",
       " 'most',\n",
       " 'd',\n",
       " 'yours',\n",
       " \"it's\",\n",
       " \"you'd\",\n",
       " \"shouldn't\",\n",
       " 'why',\n",
       " 'and',\n",
       " \"you've\",\n",
       " \"mustn't\",\n",
       " 'our',\n",
       " \"you'll\",\n",
       " 'once',\n",
       " 'it',\n",
       " 'into',\n",
       " 'this',\n",
       " 'further',\n",
       " \"wouldn't\",\n",
       " 'whom',\n",
       " 'herself',\n",
       " 'during',\n",
       " \"aren't\",\n",
       " 'so',\n",
       " 'having',\n",
       " 'has']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "new_words = [\"fig\",\"figure\",\"image\",\"sample\",\"using\",\"show\", \"result\", \"large\", \"one\", \"two\", \"three\",\"four\", \"five\", \"seven\",\"eight\",\"nine\",\"also\"]\n",
    "stop_words = list(stop_words.union(new_words))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text) \n",
    "    text = text.split()\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    text = [word for word in text if len(word) >= 3]\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    text = [lmtzr.lemmatize(word) for word in text]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       self organization associative database applica...\n",
       "1       mean field theory layer visual cortex applicat...\n",
       "2       storing covariance associative long term poten...\n",
       "3       bayesian query construction neural network mod...\n",
       "4       neural network ensemble cross validation activ...\n",
       "                              ...                        \n",
       "7236    single transistor learning synapsis paul hasle...\n",
       "7237    bias variance combination least square estimat...\n",
       "7238    real time clustering cmos neural engine serran...\n",
       "7239    learning direction global motion class psychop...\n",
       "7240    correlation interpolation network real time ex...\n",
       "Name: paper_text, Length: 7241, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = df['paper_text'].apply(lambda x:preprocessor(x))\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "countvector=CountVectorizer(max_df=0.95,max_features=10000,ngram_range=(1,3))\n",
    "wcvector=countvector.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "transformer.fit(wcvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractVector(featurenames, sorteditems, top=10):\n",
    "    sorteditems = sorteditems[:top]\n",
    "    scorevals = []\n",
    "    featurevals = []\n",
    "    for idx, score in sorteditems:\n",
    "        fname = featurenames[idx]\n",
    "        scorevals.append(round(score, 3))\n",
    "        featurevals.append(featurenames[idx])\n",
    "    results= {}\n",
    "    for idx in range(len(featurevals)):\n",
    "        results[featurevals[idx]]=scorevals[idx]  \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortedcoo(matrix):\n",
    "    tuples = zip(matrix.col, matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "feature_names=countvector.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeywords(id, doc):\n",
    "    tfidfvector=transformer.transform(cv.transform([doc[id]]))\n",
    "    sorteditems=sortedcoo(tfidfvector.tocoo())\n",
    "    keywords=extractVector(feature_names,sorteditems,10)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults(id,keyword, df):\n",
    "    # now print the results\n",
    "    print(\"\\n=====Title=====\")\n",
    "    print(df['title'][id])\n",
    "    print(\"\\n=====Abstract=====\")\n",
    "    print(df['abstract'][id])\n",
    "    print(\"\\n===Keywords===\")\n",
    "    for k in keyword:\n",
    "        print(k,keyword[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printResults(id,keywords, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
